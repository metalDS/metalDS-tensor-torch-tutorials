{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interesting-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://www.tensorflow.org/guide/keras/sequential_model\n",
    "#intro to keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-enclosure",
   "metadata": {},
   "source": [
    "the sequential model is appropriate for **a plain stack of layrs** where each layer has **exactly one input tensor and out output tensor**.\n",
    "\n",
    "the following sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaging-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "                            [\n",
    "                            layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "                            layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "                            layers.Dense(4, name=\"layer3\")\n",
    "                            ]\n",
    ")\n",
    "\n",
    "#call model on test input\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea294b-67b8-4b5c-9f14-542e1cb6ebab",
   "metadata": {},
   "source": [
    "is equivalent to this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f841a556-74ad-4727-b8b1-51a49551dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 3 layers\n",
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "y_2 = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c08e72-283a-404c-a4cd-751203ed3915",
   "metadata": {},
   "source": [
    "**creating a Sequential model:**\n",
    "\n",
    "you can creat a sequential model by passing a list of alayers to the sequential constructor (above in the second code cell)\n",
    "\n",
    "the layers are accessable via the layers attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512f2830-e08e-4879-9f21-385f037a74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.layers.core.Dense object at 0x00000250CC209AF0>, <tensorflow.python.keras.layers.core.Dense object at 0x00000250CC209760>, <tensorflow.python.keras.layers.core.Dense object at 0x00000250CC3DDDC0>]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05466ac2-37e6-41f1-8936-e532d0efb220",
   "metadata": {},
   "source": [
    "you can also add to the model, or create a model incrementally via the **add()** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054f4a3e-6964-453f-b0aa-ed830ed0cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "\n",
    "model2.add(layers.Dense(2, activation=\"relu\"))\n",
    "model2.add(layers.Dense(3, activation=\"relu\"))\n",
    "model2.add(layers.Dense(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f04a1-bd41-4821-9514-c1c590528d91",
   "metadata": {},
   "source": [
    "you can remove layers via the **pop()** function. this makes the keras model behave like a stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cefd0170-11b1-4442-917f-a364654a1cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(model2.layers))\n",
    "model2.pop()\n",
    "print(len(model2.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a4d74-e050-441a-b314-4d157eac0697",
   "metadata": {},
   "source": [
    "a sequential constructor also accepts a name argument, just like any layer. this is useful to annotate TensorBoard graphs with meaningful names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef3c4499-dd5b-4efa-884b-ffcb42ea71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential(name=\"my_sequential\")\n",
    "model3.add(layers.Dense(2, activation=\"relu\", name=\"layer1\"))\n",
    "model3.add(layers.Dense(3, activation=\"relu\", name=\"layer2\"))\n",
    "model3.add(layers.Dense(4, name=\"layer3\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda6ee8-f5d6-474f-ab54-7038dd34dcba",
   "metadata": {},
   "source": [
    "all layers need to know the shape of thier input to create their weights so, initially, a layer will have no weights. it creates weights the first time it is called on an input. so the shape of the wieghts depends on the shape of the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a42059-19bb-4cd9-a88f-db48909382ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "tf.Tensor([[1. 1. 1. 1.]], shape=(1, 4), dtype=float32)\n",
      "[<tf.Variable 'dense_10/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[-0.27112478,  0.65860194,  0.23354167,  0.06971657],\n",
      "       [ 0.2677253 ,  0.57646996, -0.7287724 ,  0.5109716 ],\n",
      "       [-0.4640098 , -0.7533757 ,  0.04875368,  0.33155388],\n",
      "       [ 0.43726653,  0.7513469 ,  0.8567032 ,  0.19465286]],\n",
      "      dtype=float32)>, <tf.Variable 'dense_10/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "layer = layers.Dense(4)\n",
    "print(layer.weights) #empty\n",
    "\n",
    "x = tf.ones((1, 4))\n",
    "print(x)\n",
    "y = layer(x)\n",
    "\n",
    "print(layer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e32d0ad-d6ac-4ade-af3a-fe3985a50976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.03014275  1.2330431   0.41022617  1.106895  ]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0d7da-a610-470b-a552-0a5865eb4927",
   "metadata": {},
   "source": [
    "this also applies to sequential models. when you instantiate a sequential model without an input shape, it isn't \"built\" just yet. the wieghts are created when the model first sees some input data.\n",
    "\n",
    "once a model is built then you can call its **sumarry()** method to display the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3f614ef-3782-4a75-ae1f-8f773627ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (3, 2)                    8         \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (3, 3)                    9         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (3, 4)                    16        \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162fc0d-4c18-4401-9cd6-91d29c76664a",
   "metadata": {},
   "source": [
    "to have the weights (randomly) intialized in advance, you pass an **Input** object to the model so it knows the expected shape of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efac8e68-6f41-4611-bc5e-918b8545d401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"another Sequential model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myModel = keras.Sequential(name=\"another Sequential model\")\n",
    "myModel.add(keras.Input(shape=(4,)))\n",
    "myModel.add(layers.Dense(2, activation=\"relu\"))\n",
    "\n",
    "myModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1849af-8fbd-46de-adc1-6849f135c451",
   "metadata": {},
   "source": [
    "alternatively you can just pass an **input_shape** optional argument to your first layer\n",
    "\n",
    "**a common debuggin workflow: add() + summary()**\n",
    "\n",
    "when building a new architecture, its useful to incrementally stack layers with add(). you can then monitor and debug the progress of the architecture with the summary() method. for example, it enables you to monitor hwo a stack of Conv2d and MaxPooling2D layers are downsampling image feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51a27f45-d606-428f-b9a0-6046402d7586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "=================================================================\n",
      "Total params: 11,680\n",
      "Trainable params: 11,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 38, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "=================================================================\n",
      "Total params: 48,672\n",
      "Trainable params: 48,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "# Can you guess what the current output shape is at this point? Probably not.\n",
    "# Let's just print it:\n",
    "model.summary()\n",
    "\n",
    "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# And now?\n",
    "model.summary()\n",
    "\n",
    "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "model.add(layers.Dense(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd005bd-885a-447e-8751-65a226f8bc1a",
   "metadata": {},
   "source": [
    "once a model is built, you will want to:\n",
    "\n",
    "train your model, evaluate it, and run inference: https://www.tensorflow.org/guide/keras/train_and_evaluate/\n",
    "save your model to disk and restore it: https://www.tensorflow.org/guide/keras/save_and_serialize/\n",
    "speed up model training by using GPU resources: https://keras.io/guides/distributed_training/\n",
    "\n",
    "**feature extraction with a Sequential Model**\n",
    "Once a Sequential model has been built, it behaves like a **functional API model** (https://www.tensorflow.org/guide/keras/functional/). meaning that every layer has **input** and **output** attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "515ee9d9-c6cc-496e-8fd9-c5771bc0969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=[layer.output for layer in initial_model.layers],\n",
    ")\n",
    "\n",
    "# Call feature extractor on test input.\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)\n",
    "\n",
    "#Here's a similar example that only extract features from one layer:\n",
    "\n",
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n",
    ")\n",
    "# Call feature extractor on test input.\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd9916-d755-444e-8ba3-b91faef14401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
